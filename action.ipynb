{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Specify the path to the UCF50 dataset folder\n",
    "data_dir = r'C:\\Users\\Admin\\OneDrive\\Desktop\\Ucfdata'\n",
    "\n",
    "# Replace placeholders with actual values\n",
    "action_category = 'Punch'\n",
    "video_name = 'v_Punch_g01_c01.avi'\n",
    "\n",
    "# Construct the path to the video file\n",
    "video_path = os.path.join(data_dir, action_category, video_name)\n",
    "\n",
    "# Example: Load the first frame of the video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if the video is successfully opened\n",
    "if not cap.isOpened():\n",
    "    print(f\"Error: Could not open video file '{video_path}'\")\n",
    "else:\n",
    "    # Read the first frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Check if the frame is successfully read\n",
    "    if ret:\n",
    "        # Display the first frame (optional)\n",
    "        cv2.imshow('First Frame', frame)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    else:\n",
    "        print(f\"Error: Could not read frame from video file '{video_path}'\")\n",
    "\n",
    "# Release the video capture object\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install opencv-python numpy scikit-learn tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\n",
      "Version: 2.15.0\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Requires: tensorflow-intel\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your parameters\n",
    "seq_len = 5  # Sequence length\n",
    "img_height, img_width = 90, 90  # Image dimensions\n",
    "\n",
    "# Load UCF50 dataset\n",
    "classes = os.listdir(data_dir)\n",
    "\n",
    "def frames_extraction(video_path):\n",
    "    frames_list = []\n",
    "    vidObj = cv2.VideoCapture(video_path)\n",
    "    count = 1\n",
    "    while count <= seq_len:\n",
    "        success, image = vidObj.read()\n",
    "        if success:\n",
    "            image = cv2.resize(image, (img_height, img_width))\n",
    "            frames_list.append(image)\n",
    "            count += 1\n",
    "        else:\n",
    "            print(\"Defected frame\")\n",
    "            break\n",
    "    return frames_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(input_dir):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for c in classes:\n",
    "        print(c)\n",
    "        files_list = os.listdir(os.path.join(input_dir, c))\n",
    "        for f in files_list[:600]:\n",
    "            frames = frames_extraction(os.path.join(os.path.join(input_dir, c), f))\n",
    "            if len(frames) == seq_len:\n",
    "                X.append(frames)\n",
    "                Y.append(c)\n",
    "    X = np.asarray(X)\n",
    "    Y = np.asarray(Y)\n",
    "    return X, Y\n",
    "\n",
    "# Create and preprocess data\n",
    "X, Y = create_data(data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the data into training, validation, and testing sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, Y, test_size=0.4, shuffle=True, random_state=1)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, shuffle=True, random_state=1)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y_train_encoded = encoder.fit_transform(y_train.reshape(-1, 1))\n",
    "y_val_encoded = encoder.transform(y_val.reshape(-1, 1))\n",
    "y_test_encoded = encoder.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Data preprocessing for Conv3D model\n",
    "X_train = X_train / 255.0\n",
    "X_val = X_val / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Data preprocessing for Isolation Forest\n",
    "X_train_flatten = X_train.reshape(X_train.shape[0], -1)\n",
    "X_val_flatten = X_val.reshape(X_val.shape[0], -1)\n",
    "X_test_flatten = X_test.reshape(X_test.shape[0], -1)\n",
    "X_train_flatten = X_train_flatten / 255.0\n",
    "X_val_flatten = X_val_flatten / 255.0\n",
    "X_test_flatten = X_test_flatten / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model for violent action detection\n",
    "model_violence = keras.Sequential()\n",
    "model_violence.add(layers.Conv3D(32, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(seq_len, img_height, img_width, 3)))\n",
    "model_violence.add(layers.MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "model_violence.add(layers.BatchNormalization(center=True, scale=True))\n",
    "model_violence.add(layers.Dropout(0.5))\n",
    "model_violence.add(layers.Conv3D(64, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "model_violence.add(layers.MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "model_violence.add(layers.BatchNormalization(center=True, scale=True))\n",
    "model_violence.add(layers.Dropout(0.5))\n",
    "model_violence.add(layers.Flatten())\n",
    "model_violence.add(layers.Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
    "model_violence.add(layers.Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
    "model_violence.add(layers.Dense(len(classes), activation='softmax'))\n",
    "\n",
    "model_violence.compile(loss='categorical_crossentropy',\n",
    "                       optimizer=keras.optimizers.Adam(lr=0.001),\n",
    "                       metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model for violent action detection\n",
    "history_violence = model_violence.fit(X_train, y_train_encoded,\n",
    "                                      batch_size=5,\n",
    "                                      epochs=25,\n",
    "                                      verbose=1,\n",
    "                                      validation_data=(X_val, y_val_encoded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model for violent action detection\n",
    "scores_violence = model_violence.evaluate(X_test, y_test_encoded)\n",
    "print(f\"Violent Action Detection Test Accuracy: {scores_violence[1]*100}\")\n",
    "y_pred_violence = model_violence.predict(X_test)\n",
    "y_pred_violence = np.argmax(y_pred_violence, axis=1)\n",
    "y_test_violence = np.argmax(y_test_encoded, axis=1)\n",
    "print(classification_report(y_test_violence, y_pred_violence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model for anomalous crowd behavior detection using Isolation Forests\n",
    "iso_forest = IsolationForest(contamination=0.1)\n",
    "iso_forest.fit(X_train_flatten)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test set\n",
    "anomaly_pred = iso_forest.predict(X_test_flatten)\n",
    "\n",
    "# Evaluate the anomalous crowd behavior detection\n",
    "anomaly_true = np.ones_like(anomaly_pred)  # Since UCF50 is not annotated for anomalies, consider all as normal\n",
    "print(\"Anomalous Crowd Behavior Detection Classification Report:\")\n",
    "print(classification_report(anomaly_true, anomaly_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of Conv3D model training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_violence.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history_violence.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Conv3D Model Training History')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_violence.history['loss'], label='Training Loss')\n",
    "plt.plot(history_violence.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Conv3D Model Training History')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Live surveillance using webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize frame buffer\n",
    "frames_buffer = []\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the webcam\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Resize the frame to match the model input size\n",
    "    frame = cv2.resize(frame, (img_width, img_height))\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Live Surveillance', frame)\n",
    "\n",
    "    # Add the frame to the buffer\n",
    "    frames_buffer.append(frame)\n",
    "\n",
    "    # Keep the buffer size equal to the sequence length\n",
    "    if len(frames_buffer) > seq_len:\n",
    "        frames_buffer.pop(0)\n",
    "\n",
    "    # Perform violence detection every seq_len frames\n",
    "    if len(frames_buffer) == seq_len:\n",
    "        # Convert frames buffer to a sequence for violence detection\n",
    "        sequence = np.asarray(frames_buffer).reshape((1, seq_len, img_height, img_width, 3))\n",
    "\n",
    "        # Predict violence using the Conv3D model\n",
    "        violence_result = model_violence.predict(sequence)\n",
    "        predicted_class = classes[np.argmax(violence_result)]\n",
    "        print(f\"Violence Detection Result: {predicted_class}\")\n",
    "\n",
    "        # Reset the buffer for the next sequence\n",
    "        frames_buffer = []\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam and close the OpenCV window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
